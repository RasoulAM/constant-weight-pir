{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation of the data\n",
    "This notebook produces the tables shown in the paper. It is assumed that the scripts in `scripts/` have been run and the results have been written to `results` directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def create_table_of_results(directory):\n",
    "    files = [filename for filename in glob.glob(\"results/\" + directory + \"/*.csv\")]\n",
    "\n",
    "    tables = [pd.read_csv(f, header=None).T for f in files]\n",
    "    for t in tables:\n",
    "        t.columns = list([t.iloc[0]])\n",
    "        t.drop(0, inplace=True)\n",
    "\n",
    "    all_results = pd.concat(tables)\n",
    "    all_results.columns = [y[0] for y in all_results.columns]    \n",
    "    return all_results\n",
    "\n",
    "def get_sig_figs(x, sig=1):\n",
    "    return round(x, -int(np.log10(x))+sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for PIR with one plaintext payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "pir_data = create_table_of_results('pir-one-plaintext')\n",
    "pir_data[\"db_size\"] = pir_data[\"num_keywords\"] * (2**pir_data[\"log_poly_mod_degree\"]) * 20 / 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folklore with N=8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = pir_data[\n",
    "    (\n",
    "        (pir_data['eq_type'] == 0) &\n",
    "        (pir_data['log_poly_mod_degree'] == 13) &\n",
    "        (pir_data['num_threads'] == 1)\n",
    "    )\n",
    "]\n",
    "selected_data = selected_data.reset_index().drop(columns=[\"index\"])\n",
    "selected_data = selected_data.astype('int64')\n",
    "\n",
    "averaged_data = selected_data.groupby([\"num_keywords\"], as_index=True).mean()\n",
    "averaged_data = averaged_data.astype('int64')\n",
    "\n",
    "for col in [\"db_size\", \"time_query\", \"time_expansion\",\"time_sel_vec\", \"time_inner_prod\", \"time_server_latency\"]:\n",
    "    averaged_data[col] = averaged_data[col].apply(lambda x: \"{:1g}\".format(get_sig_figs(x/1000000)))\n",
    "\n",
    "res = averaged_data.reset_index(level=0)[[\"num_keywords\", \"db_size\", \"encoding_size\", \"time_expansion\", \"time_sel_vec\", \"time_inner_prod\", \"time_server_latency\"]]\n",
    "res.astype('str').apply(lambda x: x + \" &\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folklore with N=16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = pir_data[\n",
    "    (\n",
    "        (pir_data['eq_type'] == 0) &\n",
    "        (pir_data['log_poly_mod_degree'] == 14) &\n",
    "        (pir_data['num_threads'] == 1)\n",
    "    )\n",
    "]\n",
    "selected_data = selected_data.reset_index().drop(columns=[\"index\"])\n",
    "selected_data = selected_data.astype('int64')\n",
    "\n",
    "averaged_data = selected_data.groupby([\"num_keywords\"], as_index=True).mean()\n",
    "averaged_data = averaged_data.astype('int64')\n",
    "\n",
    "for col in [\"db_size\", \"time_query\", \"time_expansion\", \"time_sel_vec\", \"time_inner_prod\", \"time_server_latency\"]:\n",
    "    averaged_data[col] = averaged_data[col].apply(lambda x: \"{:1g}\".format(get_sig_figs(x/1000000)))\n",
    "\n",
    "res = averaged_data.reset_index(level=0)[[\"num_keywords\", \"db_size\",  \"encoding_size\", \"time_expansion\", \"time_sel_vec\", \"time_inner_prod\", \"time_server_latency\"]]\n",
    "res.astype('str').apply(lambda x: x + \" &\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant-weight k=2 Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = pir_data[\n",
    "    (\n",
    "        (pir_data['hamming_weight'] == 2) &\n",
    "        (pir_data['eq_type'] == 1) &\n",
    "        (pir_data['num_threads'] == 1)\n",
    "    )\n",
    "]\n",
    "selected_data = selected_data.reset_index().drop(columns=[\"index\"])\n",
    "selected_data = selected_data.astype('int64')\n",
    "\n",
    "averaged_data = selected_data.groupby([\"hamming_weight\", \"num_keywords\"], as_index=True).mean()\n",
    "averaged_data = averaged_data.astype('int64')\n",
    "\n",
    "for col in [\"time_query\", \"time_expansion\",]:\n",
    "    averaged_data[col] = averaged_data[col].apply(lambda x: \"{:.1g}\".format(x/1000000))\n",
    "\n",
    "for col in [\"db_size\", \"time_sel_vec\", \"time_inner_prod\", \"time_server_latency\"]:\n",
    "    averaged_data[col] = averaged_data[col].apply(lambda x: \"{:1g}\".format(get_sig_figs(x/1000000)))\n",
    "\n",
    "averaged_data.index = averaged_data.index.droplevel(level=0)\n",
    "res = averaged_data[[\"db_size\", \"encoding_size\", \"time_expansion\", \"time_sel_vec\", \"time_inner_prod\", \"time_server_latency\"]]\n",
    "res.astype('str').apply(lambda x: x + \" &\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant-weight k=2 Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = pir_data[\n",
    "    (\n",
    "        (pir_data['hamming_weight'] == 2) &\n",
    "        (pir_data['eq_type'] == 1) &\n",
    "        (pir_data['num_threads'] == 64)\n",
    "    )\n",
    "]\n",
    "selected_data = selected_data.reset_index().drop(columns=[\"index\"])\n",
    "selected_data = selected_data.astype('int64')\n",
    "\n",
    "averaged_data = selected_data.groupby([\"hamming_weight\", \"num_keywords\"], as_index=True).mean()\n",
    "averaged_data = averaged_data.astype('int64')\n",
    "\n",
    "for col in [\"db_size\", \"time_query\", \"time_expansion\",\"time_sel_vec\", \"time_inner_prod\", \"time_server_latency\"]:\n",
    "    averaged_data[col] = averaged_data[col].apply(lambda x: \"{:1g}\".format(get_sig_figs(x/1000000)))\n",
    "\n",
    "res = averaged_data.reset_index(level=0)[[\"db_size\", \"encoding_size\", \"time_expansion\", \"time_sel_vec\", \"time_inner_prod\", \"time_server_latency\"]]\n",
    "res.astype('str').apply(lambda x: x + \" &\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unary Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = pir_data[\n",
    "    (\n",
    "        (pir_data['hamming_weight'] == 1) &\n",
    "        (pir_data['eq_type'] == 1) &\n",
    "        (pir_data['num_threads'] == 1)\n",
    "    )\n",
    "]\n",
    "selected_data = selected_data.reset_index().drop(columns=[\"index\"])\n",
    "selected_data = selected_data.astype('int64')\n",
    "\n",
    "averaged_data = selected_data.groupby([\"hamming_weight\", \"num_keywords\"], as_index=True).mean()\n",
    "averaged_data = averaged_data.astype('int64')\n",
    "\n",
    "for col in [\"time_query\", \"time_expansion\",]:\n",
    "    averaged_data[col] = averaged_data[col].apply(lambda x: \"{:1g}\".format(get_sig_figs(x/1000000)))\n",
    "\n",
    "for col in [\"db_size\", \"time_sel_vec\", \"time_inner_prod\", \"time_server_latency\"]:\n",
    "    averaged_data[col] = averaged_data[col].apply(lambda x: \"{:1g}\".format(get_sig_figs(x/1000000)))\n",
    "\n",
    "res = averaged_data.reset_index(level=0)[[\"db_size\", \"encoding_size\", \"time_expansion\", \"time_sel_vec\", \"time_inner_prod\", \"time_server_latency\"]]\n",
    "res.astype('str').apply(lambda x: x + \" &\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for Databases with Large Payloads (large databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "large_pir_data = create_table_of_results(\"pir-large-payload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for h, kw in [(2, 16), (3, 32), (4, 48)]:\n",
    "    for nk in [1000, 10000]:\n",
    "        data = large_pir_data[(large_pir_data['num_keywords'] == nk) & (large_pir_data['hamming_weight']==h) & (large_pir_data[\"valid_response\"] == 1)]\n",
    "        data = data.reset_index().drop(columns=[\"index\"])\n",
    "        data = data.astype('int64')\n",
    "        data[\"db_size\"] = (data[\"num_keywords\"] * (2**data[\"log_poly_mod_degree\"]) * data[\"num_output_ciphers\"] * 20 / 8000000000).apply(lambda x : get_sig_figs(x))\n",
    "        data[\"item_size\"] = ((2**data[\"log_poly_mod_degree\"]) * data[\"num_output_ciphers\"] * 20 / 8000000).apply(lambda x : get_sig_figs(x))\n",
    "        data = data[data.db_size >= 0.5]\n",
    "        data=  data.groupby([\"num_output_ciphers\"], as_index=True).mean()\n",
    "\n",
    "        for col in [\"time_server_latency\", \"time_expansion\", \"time_sel_vec\", \"time_inner_prod\",]:\n",
    "            data[col] = data[col].apply(lambda x: \"{:1g}\".format(get_sig_figs(x/1000000,2)))\n",
    "\n",
    "        data[\"keyword_bitlength\"] = kw\n",
    "        res = data[[\"keyword_bitlength\", \"num_keywords\", \"db_size\", \"item_size\", \"time_server_latency\",]]\n",
    "        res = res.sort_values(by=[\"db_size\"])\n",
    "        res.reset_index(drop=True, inplace=True)\n",
    "        res.set_index('keyword_bitlength', inplace=True)\n",
    "        res=res.astype('str').apply(lambda x: x + \" &\")\n",
    "        results += [res]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming_weight = 2\n",
    "# keyword bitlength = 16\n",
    "# number of rows in database = 1000\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming_weight = 2\n",
    "# keyword bitlength = 16\n",
    "# number of rows in database = 10000\n",
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming_weight = 3\n",
    "# keyword bitlength = 32\n",
    "# number of rows in database = 1000\n",
    "results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming_weight = 3\n",
    "# keyword bitlength = 32\n",
    "# number of rows in database = 10000\n",
    "results[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming_weight = 4\n",
    "# keyword bitlength = 48\n",
    "# number of rows in database = 1000\n",
    "results[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hamming_weight = 4\n",
    "# keyword bitlength = 48\n",
    "# number of rows in database = 10000\n",
    "results[5]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
